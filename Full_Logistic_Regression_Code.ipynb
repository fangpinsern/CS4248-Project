{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Full Logistic Regression Code.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AQuNFh7G0hX"
      },
      "source": [
        "#Imports\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.tag import StanfordNERTagger\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "\n",
        "import numpy as np\n",
        "import re\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF2OcFn3HDRq",
        "outputId": "c048e3f8-cc31-4a2e-d98a-67d6b0b07231"
      },
      "source": [
        "#Downloads from NLTK\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datapath = 'BALANCED_train_test_split_dataset.csv'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIvR-e5hKpr3"
      },
      "source": [
        "def train_model(model, x_train, y_train):\n",
        "  logreg = model.fit(x_train, y_train)\n",
        "  print(\"Done Training\")\n",
        "  return logreg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysIJG2_nKxK3"
      },
      "source": [
        "def predict(model, x_test):\n",
        "  pred = model.predict(x_test)\n",
        "  return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs12HaUPKy8_"
      },
      "source": [
        "def generate_result(test, y_pred, filename):\n",
        "    ''' generate csv file base on the y_pred '''\n",
        "    test['pred'] = pd.Series(y_pred)\n",
        "    test.to_csv(filename, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf-fKYhMHL9P",
        "outputId": "dd80bfbb-5a6a-447b-a603-e8f11f38ebcc"
      },
      "source": [
        "train = pd.read_csv(open(datapath, errors='ignore'))\n",
        "print(\"Dataset Imported\")\n",
        "X_train = train['headline'][train.phase == 'train']\n",
        "y_train = train['category'][train.phase == 'train']\n",
        "# vec = TfidfVectorizer()\n",
        "vec = CountVectorizer()\n",
        "X_train_Tfidf = vec.fit_transform(X_train)\n",
        "print(\"Done Vectorizing\")\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "print(\"Training model\")\n",
        "train_model(model, X_train_Tfidf, y_train)\n",
        "print(\"Done Training\")\n",
        "\n",
        "X_test = train['headline'][train.phase == 'test']\n",
        "X_test_Tfidf = vec.transform(X_test)\n",
        "y_pred = predict(model, X_test_Tfidf)\n",
        "test = train[train.phase == 'test']\n",
        "y_test = train['category'][train.phase == 'test']\n",
        "score = f1_score(y_test, y_pred, average=\"weighted\")\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print('score on validation = {}'.format(score))\n",
        "print('score on accuracy = {}'.format(acc))\n",
        "generate_result(test, y_pred, \"RESULT.csv\")\n",
        "print(\"END\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Imported\n",
            "Done Vectorizing\n",
            "Training model\n",
            "Done Training\n",
            "Done Training\n",
            "score on validation = 0.7895388791903047\n",
            "score on accuracy = 0.7928836457045001\n",
            "END\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}